import pandas as pd
import numpy as np
import os
import joblib
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

ARCHIVO_DATOS = 'entrenamiento.csv'
MODELO_SALIDA = 'modelo_conciliacion.pkl'

# Features utilizadas por la IA para predecir si es un "match"
FEATURES = ['diferencia_monto', 'diferencia_dias', 'similitud_folio', 'similitud_razon_social', 'es_mismo_monto']
TARGET = 'es_match'

def entrenar_modelo():
    print("===================================================")
    print("   üß† ENTRENAMIENTO DE IA PARA CONCILIACI√ìN üß†   ")
    print("===================================================")

    if not os.path.exists(ARCHIVO_DATOS):
        print(f"‚ùå ERROR: No se encontr√≥ el archivo de datos '{ARCHIVO_DATOS}'.")
        print("Aseg√∫rate de tener un hist√≥rico de conciliaciones previas para entrenar a la IA.")
        return

    print(f"üìÇ Cargando datos hist√≥ricos desde {ARCHIVO_DATOS}...")
    try:
        df = pd.read_csv(ARCHIVO_DATOS)
    except Exception as e:
        print(f"‚ùå ERROR al leer el archivo CSV: {e}")
        return
    
    # Validaci√≥n de columnas
    columnas_faltantes = [col for col in FEATURES + [TARGET] if col not in df.columns]
    if columnas_faltantes:
        print(f"‚ùå ERROR: Faltan las siguientes columnas en tu CSV: {columnas_faltantes}")
        return

    # Limpieza de datos nulos
    df = df.dropna(subset=FEATURES + [TARGET])
    
    if len(df) < 20:
        print("‚ö†Ô∏è ADVERTENCIA: Tienes muy pocos datos para un entrenamiento cruzado efectivo.")
        print(f"Filas actuales: {len(df)}. Se recomienda tener al menos 100 ejemplos hist√≥ricos.")

    X = df[FEATURES]
    y = df[TARGET]

    print(f"üìä Total de ejemplos para entrenar: {len(df)} (Matches reales: {int(y.sum())})")

    # Divisi√≥n de datos (80% entrenamiento, 20% prueba)
    try:
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    except ValueError as e:
        print(f"‚ùå ERROR al dividir los datos: {e}")
        print("Posible causa: Necesitas tener ejemplos de ambas clases (matches exitosos y fallidos) en tu CSV.")
        return

    print("‚öôÔ∏è Buscando la configuraci√≥n matem√°tica √≥ptima (esto puede tardar unos segundos)...")
    
    # Par√°metros para buscar el mejor modelo
    parametros_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5, 10],
        'class_weight': ['balanced']
    }

    modelo_base = RandomForestClassifier(random_state=42)
    
    # Usamos validaci√≥n cruzada para asegurar que el modelo sea robusto
    buscador = GridSearchCV(estimator=modelo_base, param_grid=parametros_grid, cv=5, scoring='accuracy', n_jobs=-1)
    
    try:
        buscador.fit(X_train, y_train)
    except Exception as e:
        print(f"‚ùå ERROR durante el entrenamiento: {e}")
        print("Si el error menciona 'splits', es porque tienes muy pocos datos en el CSV para hacer validaci√≥n cruzada (cv=5).")
        return

    mejor_modelo = buscador.best_estimator_

    print("\n‚úÖ ¬°Entrenamiento completado!")
    print(f"Mejor configuraci√≥n encontrada: {buscador.best_params_}")
    
    # Evaluaci√≥n del modelo
    predicciones = mejor_modelo.predict(X_test)
    precision = accuracy_score(y_test, predicciones)
    
    print("\n--- üìà REPORTE DE RENDIMIENTO ---")
    print(f"Precisi√≥n General (Accuracy): {precision * 100:.2f}%")
    print("\nMatriz de Confusi√≥n (V. Positivos, F. Positivos, etc.):")
    print(confusion_matrix(y_test, predicciones))
    print("\nReporte Detallado:")
    print(classification_report(y_test, predicciones))

    print("\n--- üß† IMPORTANCIA DE VARIABLES ---")
    importancias = mejor_modelo.feature_importances_
    # Ordenamos de mayor a menor importancia
    importancias_ordenadas = sorted(zip(FEATURES, importancias), key=lambda x: x[1], reverse=True)
    for feature, importancia in importancias_ordenadas:
        print(f" - {feature}: {importancia * 100:.1f}%")

    # Guardar el modelo
    try:
        joblib.dump(mejor_modelo, MODELO_SALIDA)
        print(f"\nüíæ ¬°Modelo guardado con √©xito como '{MODELO_SALIDA}'!")
        print("Tu servidor (app.py) ya puede usar esta nueva IA actualizada.")
    except Exception as e:
        print(f"‚ùå ERROR al guardar el modelo: {e}")

if __name__ == "__main__":
    entrenar_modelo()